{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from configparser import ConfigParser\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup    \n",
    "\n",
    "parser = ConfigParser()\n",
    "parser.read(\"covid_app/settings.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, parser: ConfigParser):\n",
    "        \n",
    "        self.latest_load = None\n",
    "        self.data = None\n",
    "    def load_data(self):\n",
    "        # local, external\n",
    "\n",
    "        def load_jhu():\n",
    "            error_msg = \"cannot load jhu data, no url provided\"\n",
    "            try:\n",
    "                lookup_table = pd.read_csv(parser.get(\"urls\", \"jhu_lookup_url\"))\n",
    "                lookup_table.rename(\n",
    "                    columns={\"Country_Region\": \"region\", \"Long_\": \"Lon\"}, inplace=True\n",
    "                )\n",
    "                return lookup_table\n",
    "            except:\n",
    "                print(error_msg)\n",
    "                return None\n",
    "            \n",
    "            if lookup_table:\n",
    "                def read_prepare_data(url):\n",
    "                    try:\n",
    "                        data_raw = pd.read_csv(parser.get(\"urlss\", url))\n",
    "                        data_raw.rename(columns={\"Country/Region\": \"region\"}, inplace=True)\n",
    "                        data = (\n",
    "                            data_raw.groupby(\"region\")\n",
    "                            .sum()\n",
    "                            .drop(columns=[\"Lat\", \"Long\"])\n",
    "                            .reset_index()\n",
    "                        )\n",
    "\n",
    "                        return data\n",
    "                    except:\n",
    "                        print(error_msg)\n",
    "                        return None\n",
    "                \n",
    "                def create_timeseries(data, lookup_table, value_name):\n",
    "                    try:\n",
    "                        \n",
    "                        id_vars = \"region\"\n",
    "                        var_name = \"date\"\n",
    "                        timeseries = pd.melt(\n",
    "                            data, id_vars=id_vars, var_name=var_name, value_name=value_name\n",
    "                        )\n",
    "                        timeseries = pd.merge(\n",
    "                            lookup_table[[\"iso2\", \"iso3\", \"code3\", \"Lat\", \"Lon\", id_vars]]\n",
    "                            .groupby(id_vars)\n",
    "                            .first(),\n",
    "                            timeseries,\n",
    "                            on=id_vars,\n",
    "                            how=\"inner\",\n",
    "                        )\n",
    "                        timeseries.loc[:, var_name] = pd.to_datetime(timeseries.loc[:, var_name])\n",
    "                        return timeseries\n",
    "                    except:\n",
    "                        print(error_msg)\n",
    "                        return None\n",
    "                        \n",
    "\n",
    "                confirmed_data = read_prepare_data(\"jhu_confirmed_url\")\n",
    "                deaths_data = read_prepare_data(\"jhu_deaths_url\")\n",
    "                recovered_data = read_prepare_data(\"jhu_recovered_url\")\n",
    "\n",
    "                confirmed = create_timeseries(confirmed_data, lookup, \"confirmed\")\n",
    "                deaths = create_timeseries(deaths_data, lookup, \"deaths\")\n",
    "                recovered = create_timeseries(recovered_data, lookup, \"recovered\")\n",
    "\n",
    "                data = pd.merge(\n",
    "                    deaths[[\"date\", \"region\", \"iso3\", \"Lat\", \"Lon\", \"deaths\"]],\n",
    "                    confirmed[[\"date\", \"confirmed\", \"iso3\"]],\n",
    "                    on=[\"iso3\", \"date\"],\n",
    "                    how=\"inner\",\n",
    "                )\n",
    "                data = pd.merge(\n",
    "                    data,\n",
    "                    recovered[[\"date\", \"recovered\", \"iso3\"]],\n",
    "                    on=[\"iso3\", \"date\"],\n",
    "                    how=\"inner\",\n",
    "                )\n",
    "\n",
    "                data.rename(columns={\"confirmed\": \"cases\"}, inplace=True)\n",
    "\n",
    "                return data\n",
    "                \n",
    "            else:\n",
    "                print(error)\n",
    "                return None\n",
    "            \n",
    "                \n",
    "                \n",
    "        self.latest_load = datetime.now()\n",
    "        self.data = load_jhu()\n",
    "    def prepare(self):\n",
    "        # join tables, create timeseries\n",
    "        pass\n",
    "    def write_data(self):\n",
    "        # to csv\n",
    "        if self.data is not None:\n",
    "            self.data.to_csv(\"test.csv\")\n",
    "        else:\n",
    "            print(\"nothing to write\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 ms, sys: 2.33 ms, total: 21.8 ms\n",
      "Wall time: 65.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>AO</td>\n",
       "      <td>AGO</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866268.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UID iso2 iso3  code3  FIPS Admin2 Province_State       region       Lat  \\\n",
       "0    4   AF  AFG    4.0   NaN    NaN            NaN  Afghanistan  33.93911   \n",
       "1    8   AL  ALB    8.0   NaN    NaN            NaN      Albania  41.15330   \n",
       "2   12   DZ  DZA   12.0   NaN    NaN            NaN      Algeria  28.03390   \n",
       "3   20   AD  AND   20.0   NaN    NaN            NaN      Andorra  42.50630   \n",
       "4   24   AO  AGO   24.0   NaN    NaN            NaN       Angola -11.20270   \n",
       "\n",
       "         Lon Combined_Key  Population  \n",
       "0  67.709953  Afghanistan  38928341.0  \n",
       "1  20.168300      Albania   2877800.0  \n",
       "2   1.659600      Algeria  43851043.0  \n",
       "3   1.521800      Andorra     77265.0  \n",
       "4  17.873900       Angola  32866268.0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "load = Loader(parser)\n",
    "load.load_data()\n",
    "load.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-06 07:49:51.352032\n",
      "   Rank           name      pop2019  pop2018  GrowthRate       area   Density\n",
      "0     1          China  1433783.686      NaN      1.0039  9706961.0  147.7068\n",
      "1     2          India  1366417.754      NaN      1.0099  3287590.0  415.6290\n",
      "2     3  United States   329064.917      NaN      1.0059  9372610.0   35.1092\n",
      "3     4      Indonesia   270625.568      NaN      1.0107  1904569.0  142.0928\n",
      "4     5       Pakistan   216565.318      NaN      1.0200   881912.0  245.5634\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/ditori1976/covid_app/master/data/countries.csv\"\n",
    "load = Loader(url)\n",
    "load.load_data()\n",
    "print(load.latest_load)\n",
    "print(load.data.head())\n",
    "load.write_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no url provided\n",
      "nothing to write\n"
     ]
    }
   ],
   "source": [
    "load = Loader()\n",
    "load.load_data()\n",
    "load.write_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Loader):\n",
    "    def __init__(self):\n",
    "        super().__init__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': <__main__.Data at 0x7f82f3ee6588>, 'latest_load': None, 'data': None}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data()\n",
    "\n",
    "print(data.latest_load) # latest_load not callable!\n",
    "\n",
    "data.__dict__#.keys()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('venv-covid_app')",
   "metadata": {
    "interpreter": {
     "hash": "de70414b133dab5292bcb0f2d18357df8e6d3646e04cb5bf3f5b6a578e2cb119"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}