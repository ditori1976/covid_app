{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "datetime.datetime(2020, 5, 7, 17, 42, 23, 212324)"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from application.data.data_loader import DataLoader\n",
    "from configparser import ConfigParser\n",
    "parser = ConfigParser()\n",
    "parser.read(\"settings.ini\")\n",
    "data_load = DataLoader(parser)\n",
    "data_load.load_data()\n",
    "data_load.latest_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "data_load.data.columns.any() in ['date', 'region', 'iso3', 'Lat', 'Lon', 'deaths', 'cases', 'recovered']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cannot load jhu data, no url provided\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "datetime.datetime(2020, 5, 7, 17, 27, 32, 701867)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "data_load = DataLoader(parser)\n",
    "data_load.load_data()\n",
    "data_load.latest_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from configparser import ConfigParser\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, parser: ConfigParser):\n",
    "        \n",
    "        self.latest_load = None\n",
    "        self.data = None\n",
    "    def load_data(self):\n",
    "        # local, external\n",
    "\n",
    "        def load_jhu():\n",
    "            error_msg = \"cannot load jhu data, no url provided\"\n",
    "            try:\n",
    "                lookup_table = pd.read_csv(parser.get(\"urls\", \"jhu_lookup_url\"))\n",
    "                lookup_table.rename(\n",
    "                    columns={\"Country_Region\": \"region\", \"Long_\": \"Lon\"}, inplace=True\n",
    "                )\n",
    "                return lookup_table\n",
    "            except:\n",
    "                print(error_msg)\n",
    "                return None\n",
    "            \n",
    "            if lookup_table:\n",
    "                def read_prepare_data(url):\n",
    "                    try:\n",
    "                        data_raw = pd.read_csv(parser.get(\"urlss\", url))\n",
    "                        data_raw.rename(columns={\"Country/Region\": \"region\"}, inplace=True)\n",
    "                        data = (\n",
    "                            data_raw.groupby(\"region\")\n",
    "                            .sum()\n",
    "                            .drop(columns=[\"Lat\", \"Long\"])\n",
    "                            .reset_index()\n",
    "                        )\n",
    "\n",
    "                        return data\n",
    "                    except:\n",
    "                        print(error_msg)\n",
    "                        return None\n",
    "                \n",
    "                def create_timeseries(data, lookup_table, value_name):\n",
    "                    try:\n",
    "                        \n",
    "                        id_vars = \"region\"\n",
    "                        var_name = \"date\"\n",
    "                        timeseries = pd.melt(\n",
    "                            data, id_vars=id_vars, var_name=var_name, value_name=value_name\n",
    "                        )\n",
    "                        timeseries = pd.merge(\n",
    "                            lookup_table[[\"iso2\", \"iso3\", \"code3\", \"Lat\", \"Lon\", id_vars]]\n",
    "                            .groupby(id_vars)\n",
    "                            .first(),\n",
    "                            timeseries,\n",
    "                            on=id_vars,\n",
    "                            how=\"inner\",\n",
    "                        )\n",
    "                        timeseries.loc[:, var_name] = pd.to_datetime(timeseries.loc[:, var_name])\n",
    "                        return timeseries\n",
    "                    except:\n",
    "                        print(error_msg)\n",
    "                        return None\n",
    "                        \n",
    "\n",
    "                confirmed_data = read_prepare_data(\"jhu_confirmed_url\")\n",
    "                deaths_data = read_prepare_data(\"jhu_deaths_url\")\n",
    "                recovered_data = read_prepare_data(\"jhu_recovered_url\")\n",
    "\n",
    "                confirmed = create_timeseries(confirmed_data, lookup, \"confirmed\")\n",
    "                deaths = create_timeseries(deaths_data, lookup, \"deaths\")\n",
    "                recovered = create_timeseries(recovered_data, lookup, \"recovered\")\n",
    "\n",
    "                data = pd.merge(\n",
    "                    deaths[[\"date\", \"region\", \"iso3\", \"Lat\", \"Lon\", \"deaths\"]],\n",
    "                    confirmed[[\"date\", \"confirmed\", \"iso3\"]],\n",
    "                    on=[\"iso3\", \"date\"],\n",
    "                    how=\"inner\",\n",
    "                )\n",
    "                data = pd.merge(\n",
    "                    data,\n",
    "                    recovered[[\"date\", \"recovered\", \"iso3\"]],\n",
    "                    on=[\"iso3\", \"date\"],\n",
    "                    how=\"inner\",\n",
    "                )\n",
    "\n",
    "                data.rename(columns={\"confirmed\": \"cases\"}, inplace=True)\n",
    "\n",
    "                return data\n",
    "                \n",
    "            else:\n",
    "                print(error)\n",
    "                return None\n",
    "            \n",
    "                \n",
    "                \n",
    "        self.latest_load = datetime.now()\n",
    "        self.data = load_jhu()\n",
    "    def prepare(self):\n",
    "        # join tables, create timeseries\n",
    "        pass\n",
    "    def write_data(self):\n",
    "        # to csv\n",
    "        if self.data is not None:\n",
    "            self.data.to_csv(\"test.csv\")\n",
    "        else:\n",
    "            print(\"nothing to write\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<configparser.ConfigParser at 0x10f1a5b90>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "parser = ConfigParser()\n",
    "parser.read(\"settings.ini\")\n",
    "parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv'"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "parser.get(\"urls\", \"jhu_lookup_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020-05-07 17:19:34.554463\n   Rank           name      pop2019  pop2018  GrowthRate       area   Density\n0     1          China  1433783.686      NaN      1.0039  9706961.0  147.7068\n1     2          India  1366417.754      NaN      1.0099  3287590.0  415.6290\n2     3  United States   329064.917      NaN      1.0059  9372610.0   35.1092\n3     4      Indonesia   270625.568      NaN      1.0107  1904569.0  142.0928\n4     5       Pakistan   216565.318      NaN      1.0200   881912.0  245.5634\n"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/ditori1976/covid_app/master/data/countries.csv\"\n",
    "load = Loader(url)\n",
    "load.load_data()\n",
    "print(load.latest_load)\n",
    "print(load.data.head())\n",
    "load.write_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no url provided\n",
      "nothing to write\n"
     ]
    }
   ],
   "source": [
    "load = Loader()\n",
    "load.load_data()\n",
    "load.write_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Loader):\n",
    "    def __init__(self):\n",
    "        super().__init__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': <__main__.Data at 0x7f82f3ee6588>, 'latest_load': None, 'data': None}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data()\n",
    "\n",
    "print(data.latest_load) # latest_load not callable!\n",
    "\n",
    "data.__dict__#.keys()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('venv-covid_app': venv)",
   "language": "python",
   "name": "python37764bitvenvcovidappvenvdec448b7499a496b82740a9af93e4c30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}